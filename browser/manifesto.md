## **The gib.gg Manifesto: Tools Should Empower Creators—Not Divide Them**

For over thirty years, the Doom community has kept a 1993 game alive through passion, creativity, and relentless experimentation. Mappers, coders, musicians, artists, and engine developers built one of the most vibrant modding ecosystems in the history of gaming—and they did it by embracing new tools, not fearing them.

### **Our Shared Principle**

We believe in a simple idea: **Creators deserve the freedom to use the tools that help them create.**

Whether that tool is DEU, a BSP optimizer, SLADE, UDB, Git, Copilot, or a modern LLM, the philosophy is the same:
**Better tools allow more people to build more things.**

### **The Problem We See**

Recently, parts of the Doom community have begun embracing "purity spirals"—ideological gatekeeping around what tools are "allowed" or "acceptable." This includes hostility toward anything related to AI, even when used purely as infrastructure, automation, documentation, or mundane engineering support.

This trend doesn't protect the community.

When creators are told that their workflows must pass an ideological purity test, at least three undesirable outcomes follow:

1. **People stop contributing altogether.**
   Skilled developers won't engage with communities that attack their process instead of their results.

2. **People start hiding their workflows.**
   The pressure to appear "pure" encourages secrecy, closed-source work, and dishonesty—not openness.

3. **Endless drama** where developers, both new and established, are constantly forced to defend their tooling against people who've already decided what they see as "right" and therefore lack motivation to engage in good-faith dialogue. The developers are also unmotivated to engage in good-faith dialogue when critics loudly showcase their lack of experience in either software engineering or intellectual property law. There is no middle ground where conversation prevails; the critics come across as ignorant zealots, and the developers come across as pompous assholes.

This is the opposite of what made Doom thrive. And the community is already paying the price.

### **The Reality of Modern Software**

Every toolchain today—from compilers to IDEs to graphics software—contains automation, heuristics, or machine-assisted features. Drawing a bright moral line around "AI" is both impossible and counterproductive.

Seasoned developers who adopt AI tooling often experience an [unbelievable increase in productivity](https://antirez.com/news/158). The idea of "hand-written code" is quickly becoming an esoteric novelty to us, as so many of our projects otherwise carry impractically large technical debts. It's not a matter of skill, motivation, or laziness—it has everything to do with the sheer number of work hours needed to deliver the features you love. This is a bittersweet feeling that some well-known developers resist, and justifiably so. With the excitement comes a palpable sense of loss.

The use of these tools does not innately diminish human creativity, and the solution is not their outright rejection.

### **On Legal Concerns: The Reality vs. the Panic**

A lot of anxiety around AI tools comes from claims about "legal issues" that supposedly make any AI-assisted project radioactive. It's important to be honest here: **none of these claims have ever been tested in court, let alone in a context that matters to us.** Despite the volume of discourse, the actual legal landscape is simple:

* **No AI-assisted software project has ever been successfully challenged in court.**
  Not in commercial software.
  Not in open-source software.
  Not in modding.
  **There is zero case law** establishing that code generated with the help of an AI system creates copyright liability.

* **The fears around the DMCA in relation to code generation are entirely speculative.**
  The DMCA's takedown mechanism requires a *concrete claim of ownership* over *specific copied material*.
  For AI-generated source code, that threshold has *never been met*, *never tested*, and *never validated* by any court.
  There is no legal precedent suggesting that an AI-assisted for-loop, struct layout, or algorithm template triggers DMCA liability.

* **Artwork and code are legally distinct.**
  Visual art cases involve totally different legal frameworks (style, likeness, derivative imagery, scraping practices).
  These do **not** translate cleanly—or at all—to code.
  Conflating the two only spreads misinformation and fear.

* **"AI outputs are automatically copyrighted by someone else" is not a legal fact.**
  It's an online talking point.
  Courts have not ruled this way, regulators have not adopted this view, and no plaintiff has successfully argued it.

* **"This snippet came from a code generator"**, while not a universal shield, could realistically be a *strong defense* because courts care about how the code ended up in your project: it establishes chain of custody, undermines the idea of "access", makes "substantial similarity" harder to prove, and reframes the liability in terms of model training.

* **There has never been a lawsuit proving that AI-generated code constitutes a GPL violation.** Virtually every lawsuit that hinged on the terms of GPL constitute enforcement action where a party used GPL code in a way that requires releasing their own source, but failed to do so. GPL litigation is about compliance, not "unlicensed code written with AI."

We should absolutely acknowledge that the law may evolve, and ongoing litigation could eventually clarify things. But right now—today—the idea that AI-assisted coding puts open-source projects or Doom mods at legal/DMCA risk is not supported by real-world evidence. It is a hypothetical fear, not an established reality. 

What *is* real is the way these speculative fears are used socially: **to shame, pressure, or gatekeep creators** even though the legal foundation for that pressure is nonexistent.

The Doom community has always thrived on experimentation. Rejecting tools based on untested hypotheticals only chills creativity and collaboration without offering actual protection.

### **The Reality of Harm**

Modern AI isn't benign. The growing demand for training and inference hardware has had real consequences for gamers, creators, and hobbyists. We've watched GPUs, high-bandwidth memory, and even DRAM prices spike—not because gamers suddenly demanded more, but because massive data centers now compete directly with consumers for the same silicon. This isn't imaginary, and it isn't trivial. When a graphics card doubles in price, or when memory kits become inflated overnight, the people who feel it most are exactly the kinds of individuals who keep modding communities alive.

There are other harms too:

- Consolidation of computing power into a handful of corporations
- Ethical concerns around data sourcing and model training
- The environmental and communal/social cost of running enormous data centers
- The tendency of hype cycles to distort expectations and devalue human contribution
- The enshittification of everything via low quality "AI slop"

These issues deserve real scrutiny, and they shouldn't be brushed aside. Holding companies accountable is healthy. Demanding transparency is healthy. Wanting an affordable GPU so you can play games, make mods, or compile maps is more than reasonable—it's essential to a thriving creative ecosystem.

**But recognizing these harms does not require hostility toward individual creators who use modern tools to build things.** Critiquing the industry is not the same as policing personal workflows. The hardware situation is a structural problem, not something caused by developers using a code assistant, a texture upscaler, or an automated documentation tool.

Regarding "AI slop", there has never been a shortage of WADs that could accurately be described as "non-AI slop". They are never played, never discussed, and their existence causes no harm. The cream always floats to the top in the Doom community. However, this isn't universally true, and we need to encourage criticism of such corner-cutting *where it actually matters*: when the authentic original is involuntarily substituted for an inferior "AI" simulacrum. This is always done as a matter of profitability, never passion, and rightfully offends everyone. WADs and code produced with both passion and AI tooling fall into a completely different category, even if it's low quality, *because it's never forced on you in lieu of the real deal.*

### **Our Position at gib.gg**

We can ruthlessly criticize the system while still supporting each other as creators.<br>
We will never police creativity.<br>
We will never enforce ideological purity around how something is made.<br>
We evaluate creative works by their **quality**, **craftsmanship**, and **impact**—not by the internal workflow of the developer.<br>
We support transparency and honesty.<br>
We encourage open collaboration and modern tools.<br>
We encourage any and all criticism of AI itself.<br>
We celebrate the people who build things—not the politics of how they built them.

### **A Better Path Forward**

The Doom community thrives when it is inclusive of techniques, styles, technologies, and levels of experience. Gatekeeping and purity tests achieve nothing but fragmentation.

If we want another thirty years of Doom, we need to empower creators, not discourage them.

Let's build.<br>
Let's experiment.<br>
Let's keep Doom alive by embracing the same spirit of innovation that started this journey in the first place.
